{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "property_prediction_exercise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yala/introML_chem/blob/master/lab2/property_prediction_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA8LLAO9dchw",
        "colab_type": "text"
      },
      "source": [
        "# Property Prediction Exercise!\n",
        "In this exercise, you'll extend on the tutorial from lab1 to implement neural networks to predict log p from Morgan Fingerprints. \n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT_jLzv8do9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision==0.2.0\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y --prefix /usr/local -c conda-forge rdkit rdkit scikit-learn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcLJrU16dch0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from typing import Union, List, Dict\n",
        "import argparse\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "print( sys.version)\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "!wget https://raw.githubusercontent.com/yala/introML_chem/master/lab1/data/chem/delaney_train.csv\n",
        "!wget https://raw.githubusercontent.com/yala/introML_chem/master/lab1/data/chem/delaney_val.csv\n",
        "!wget https://raw.githubusercontent.com/yala/introML_chem/master/lab1/data/chem/delaney_test.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMJfz2f-JC9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def morgan_fingerprint(smiles: str, radius: int = 3, num_bits: int = 2048) -> np.ndarray:\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "  morgan_vect = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n",
        "  morgan_fp = np.zeros((1,))\n",
        "  DataStructs.ConvertToNumpyArray(morgan_vect, morgan_fp)\n",
        "  \n",
        "  return morgan_fp\n",
        "\n",
        "class MoleculeDatapoint:\n",
        "  def __init__(self, smiles: str, target: float):\n",
        "    self.smiles = smiles\n",
        "    self.target = target\n",
        "    self.morgan = morgan_fingerprint(smiles)\n",
        "    \n",
        "class MoleculeDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data: List[MoleculeDatapoint]):\n",
        "    self.data = data\n",
        "    \n",
        "  def smiles(self) -> List[str]:\n",
        "    return [d.smiles for d in self.data]\n",
        "  \n",
        "  def targets(self) -> List[float]:\n",
        "    return [d.target for d in self.data]\n",
        "  \n",
        "  def morgans(self) -> List[np.ndarray]:\n",
        "    return [d.morgan for d in self.data]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, i):\n",
        "    return self.data[i].morgan,  self.data[i].target\n",
        "\n",
        "def get_data(split: str) -> MoleculeDataset:\n",
        "  data_path = 'delaney_{}.csv'.format(split)\n",
        "  with open(data_path) as f:\n",
        "    f.readline()\n",
        "    data = []\n",
        "    for line in f:\n",
        "      smiles, target = line.strip().split(',')\n",
        "      target = float(target)\n",
        "      data.append(MoleculeDatapoint(smiles, target))\n",
        " \n",
        "      \n",
        "  return MoleculeDataset(data)\n",
        "\n",
        "\n",
        "def rmse(targets: List[float], preds: List[float]) -> float:\n",
        "    return math.sqrt(mean_squared_error(targets, preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bj2JcZ_M1d6",
        "colab_type": "text"
      },
      "source": [
        "## Prepare your dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUI6qciqMEyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load train/val/test data\n",
        "train = get_data('train')\n",
        "dev = get_data('val')\n",
        "test = get_data('test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYoAMl8xw4jY",
        "colab_type": "text"
      },
      "source": [
        "## Define your Model and Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhlUt5DANWlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training settings\n",
        "batch_size = pass\n",
        "epochs = pass\n",
        "lr = pass\n",
        "momentum = pass\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "\n",
        "model = Model()\n",
        "optimizer = pass\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = torch.utils.data.DataLoader(dev, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vor24RSNzHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for batch in train_loader:\n",
        "  print(batch[0].shape)\n",
        "  print(batch[1].shape)\n",
        "  \n",
        "  break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9hvStGzdcjC",
        "colab_type": "text"
      },
      "source": [
        "## Define your training procedure\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAl05-rTdcjH",
        "colab_type": "text"
      },
      "source": [
        "To train our model:\n",
        "\n",
        "1) we'll randomly sample batches from our train loader\n",
        "\n",
        "2) compute our loss (using standard `cross_entropy`)\n",
        "\n",
        "3) compute our gradients (by calling `backward()` on our loss)\n",
        "\n",
        "4) update our neural network with an `optimizer.step()`, and go back to 1)\n",
        "\n",
        "I've added some extra stuff here to log our accuracy and avg loss for the epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxIj0eWsdcjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch( model, train_loader, optimizer, epoch):\n",
        "    model.train() # Set the nn.Module to train mode. \n",
        "    total_loss = 0\n",
        "    num_samples = len(train_loader.dataset)\n",
        "    for batch_idx, (x, target) in enumerate(train_loader): #1) get batch\n",
        "        x = x.float()\n",
        "        target = target.float()\n",
        "        # Reset gradient data to 0\n",
        "        pass\n",
        "        # Get prediction for batch\n",
        "        output = model(x).squeeze(1)\n",
        "        # 2) Compute loss (hint: MSE!)\n",
        "        loss = pass\n",
        "        #3) Do backprop\n",
        "        pass\n",
        "        #4) Update model\n",
        "        pass\n",
        "\n",
        "        total_loss += loss.detach() # Don't keep computation graph \n",
        "\n",
        "    print('Train Epoch: {} \\tMSE: {:.4f})\\n'.format(\n",
        "            epoch, total_loss / num_samples))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGZnlI58dcjN",
        "colab_type": "text"
      },
      "source": [
        "## Define our evaluation loop\n",
        "Similar to above, we'll also loop through our dev or test set, and compute our loss and accuracy. \n",
        "This lets us see how well our model is generalizing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPzqSuY3dcjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_epoch(model, test_loader, name):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data = data.float()\n",
        "        target = target.float()\n",
        "        output = model(data).squeeze(-1)\n",
        "        test_loss += pass\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\n{} set: Average MSE: {:.4f}\\n'.format(\n",
        "        name,\n",
        "        test_loss))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp9H5tWEdcjR",
        "colab_type": "text"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVpU_N0idcjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_epoch(model, train_loader, optimizer, epoch)\n",
        "    eval_epoch(model,  dev_loader, \"Dev\")\n",
        "    print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNWqKY72dcjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_epoch(model,  test_loader, \"Test\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}