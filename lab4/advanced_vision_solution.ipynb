{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "advanced_vision_solution.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yala/deeplearning_bootcamp/blob/master/lab4/advanced_vision_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA8LLAO9dchw",
        "colab_type": "text"
      },
      "source": [
        "# Advanced Computer Vision Exercise: CIFAR 10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT_jLzv8do9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "\n",
        "!pip install torch torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcLJrU16dch0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoX9FXdRCKVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z11d818rdcir",
        "colab_type": "text"
      },
      "source": [
        "# The Task: CIFAR10\n",
        "<img src=\"https://corochann.com/wp-content/uploads/2017/04/cifar10_plot.png\">\n",
        "\n",
        "## Step 1: Loading Data and Preprocessing\n",
        "Let's start by loading the data.\n",
        "We're going to normalize our images to have 0 mean, and unit variance. We'll do this using some [torchvision](https://pytorch.org/docs/stable/torchvision/index.html) transforms. This generally helps stablize learning, and is common practice. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moG_DE1ldcis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Img mean value of .13, and stdv of .31 were computed across entire train set\n",
        "# in prior work\n",
        "normalize_image = transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.49,.48,.44), (0.25,.24,.26))\n",
        "                ])\n",
        "\n",
        "# Dataset is loaded fro torchvision\n",
        "all_train = datasets.CIFAR10('data', train=True, download=True, transform=normalize_image)\n",
        "\n",
        "num_train = int(len(all_train)*.8)\n",
        "train = [all_train[i] for i in range(num_train)]\n",
        "dev = [all_train[i] for i in range(num_train,len(all_train))]\n",
        "test = datasets.CIFAR10('data', train=False, download=True, \n",
        "                      transform=normalize_image)\n",
        "                           \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHq9MwYVdci5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[0][0].size()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxIj0eWsdcjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch( model, train_loader, optimizer, epoch):\n",
        "    model.train() # Set the nn.Module to train mode. \n",
        "    model = model.to('cuda')\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    num_samples = len(train_loader.dataset)\n",
        "    for batch_idx, (x, target) in enumerate(train_loader): #1) get batch\n",
        "        x, target = x.to('cuda'), target.to('cuda')\n",
        "        B, C, H, W = x.size()\n",
        "        x = x.expand([B,3,H,W]).contiguous()\n",
        "        # Reset gradient data to 0\n",
        "        optimizer.zero_grad()\n",
        "        # Get prediction for batch\n",
        "        output = model(x)\n",
        "        # 2) Compute loss\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        #3) Do backprop\n",
        "        loss.backward()\n",
        "        #4) Update model\n",
        "        optimizer.step()\n",
        "        \n",
        "        ## Do book-keeping to track accuracy and avg loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total_loss += loss.detach() # Don't keep computation graph \n",
        "\n",
        "    print('Train Epoch: {} \\tLoss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "            epoch, total_loss / num_samples, \n",
        "            correct, \n",
        "            num_samples,\n",
        "            100. * correct / num_samples))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPzqSuY3dcjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_epoch(model, test_loader, name):\n",
        "    model = model.to('cuda')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to('cuda'), target.to('cuda')\n",
        "        B, C, H, W = data.size()\n",
        "        data = data.expand([B,3,H,W]).contiguous()\n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target).item() # sum up batch loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        name,\n",
        "        test_loss, \n",
        "        correct, \n",
        "        len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2jGlFlidci-",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Building a model\n",
        "\n",
        "All pytorch models should be implemented as instances of `nn.Module`. \n",
        "\n",
        "Try your own custom model or use a pretrained one from torchvision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0NnnFWgdci-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Ht1mhhdcjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training settings\n",
        "epochs = 10\n",
        "lr = 1e-3\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = torch.utils.data.DataLoader(dev, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVpU_N0idcjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_epoch(model, train_loader, optimizer, epoch)\n",
        "    eval_epoch(model,  dev_loader, \"Dev\")\n",
        "    print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNWqKY72dcjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_epoch(model,  test_loader, \"Test\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}